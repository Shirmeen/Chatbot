from crewai import Agent, Task, Crew
from langchain_groq import ChatGroq
from dotenv import load_dotenv
import os

# Load .env for API key
load_dotenv()

# Initialize LLM
llm = ChatGroq(
    model_name="groq/llama3-8b-8192",
    api_key=os.getenv("GROQ_API_KEY"),
    temperature=0.3
)

# === AGENTS FROM FLOWCHART ===

requirement_analyzer = Agent(
    role='Requirement Analyzer 🕵️',
    goal='Analyze non-technical client input and extract the technical skills required for the task',
    backstory="""Specializes in interpreting non-technical project descriptions from clients and identifying the technical tools, libraries, or frameworks needed to implement it.""",
    llm=llm,
    verbose=True
)

skill_comparer = Agent(
    role='Skill Comparer 🤹',
    goal='Compare developer skills with required client skills',
    backstory="""Takes in two skill lists and identifies matches and missing skills.""",
    llm=llm,
    verbose=True
)

relation_mapper = Agent(
    role='Relation Mapper 🔗',
    goal='Map missing skills to related or transferable skills and assess difficulty level',
    backstory="""Helps identify if the missing skills can be quickly learned or need external expertise. If the missing and known skills are from similar domains (e.g. Python and Flask), mark them as easy to learn.""",
    llm=llm,
    verbose=True
)

confidence_scorer = Agent(
    role='Confidence Scorer ⭐',
    goal='Score the confidence of fulfilling the client requirements',
    backstory="""Uses skill match ratio and mapping to assign a percentage confidence level.""",
    llm=llm,
    verbose=True
)

# === SAMPLE INPUTS ===
non_technical_description = "I want to build a chatbot that answers customer questions using information from our product manuals. It should sound smart and respond fast, even when lots of people ask at once."
developer_skills = ["Python",
    "React",
    "AWS",
    "LangChain",
    "Docker",
    "PyTorch",
    "TensorFlow",
    "FastAPI",
    "Flask",
    "PostgreSQL",
    "MongoDB",
    "JavaScript",
    "TypeScript",
    "Node.js",
    "Git",
    "Linux",
    "Kubernetes",
    "Redis",
    "GraphQL",
    "HTML",
    "CSS"
]

# === INTERACTIVE WORKFLOW ===
if __name__ == "__main__":
    print("\n✨ Agent Workflow Starting...\n")

    # Step 1: Requirement Analysis (simulate agent output)
    extracted_skills = ["LangChain", "Flask", "Kubernetes", "GPT-4"]  # This would be generated by the Requirement Analyzer
    print("Extracted Skills from Client Requirement:", extracted_skills)

    # Step 2: Skill Comparison
    matched_skills = list(set(developer_skills) & set(extracted_skills))
    missing_skills = list(set(extracted_skills) - set(developer_skills))
    print("\nMatched Skills:", matched_skills)
    print("Missing Skills:", missing_skills)

    # Step 3: Relation Mapping with similarity analysis
    mapped_output = {}
    for skill in missing_skills:
        if skill == "Kubernetes":
            mapped_output[skill] = "Kubernetes -> Docker (Overlap, Moderate to Learn)"
        elif skill == "GPT-4":
            mapped_output[skill] = "GPT-4 -> PyTorch (Hard, Needs external help)"
        elif skill == "Flask" and "Python" in developer_skills:
            mapped_output[skill] = "Flask -> Python (Same language, Easy to Learn)"
        else:
            mapped_output[skill] = f"{skill} -> Unknown match (Assess manually)"

    print("\nSkill Relation Mapping:")
    for skill, explanation in mapped_output.items():
        print(f"- {skill}: {explanation}")

    # Step 4: Confidence Score
    easy_skills = [skill for skill, explanation in mapped_output.items() if "Easy to Learn" in explanation]
    confidence_boost = len(easy_skills) * 10
    total = len(extracted_skills)
    matched = len(matched_skills)
    base_confidence = int((matched / total) * 100)
    confidence_score = min(base_confidence + confidence_boost, 100)
    print(f"\nConfidence Score: {confidence_score}%")
